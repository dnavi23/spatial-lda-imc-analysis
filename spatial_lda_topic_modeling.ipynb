{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spatial Topic Modeling for IMC Data Analysis\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates the application of **Latent Dirichlet Allocation (LDA) topic modeling** to Imaging Mass Cytometry (IMC) data to discover spatial cellular organization patterns (spatial motifs).\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ What This Notebook Does\n",
        "\n",
        "### The Big Idea\n",
        "Just as topic modeling discovers themes in documents by analyzing word co-occurrence, **spatial topic modeling** discovers recurring patterns of cell type co-occurrence in tissue space. This helps identify:\n",
        "- **Spatial motifs**: Recurring cellular neighborhoods (e.g., \"tumor-immune interface\", \"lymphoid aggregates\")\n",
        "- **Tissue organization**: How different cell types organize spatially\n",
        "- **Biological structures**: Functionally relevant spatial patterns\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "**1. Spatial LDA Analogy**\n",
        "- **Documents** = Cell neighborhoods (spatial regions around each cell)\n",
        "- **Words** = Cell phenotypes/types found in each neighborhood\n",
        "- **Topics** = Spatial motifs (recurring patterns of cell type co-occurrence)\n",
        "\n",
        "**2. Why Coherence Analysis?**\n",
        "- Scimap's `spatial_lda` requires you to specify the number of topics (`num_motifs`)\n",
        "- Choosing this number arbitrarily can lead to suboptimal results\n",
        "- **Coherence analysis** tests multiple topic numbers and selects the one with highest coherence (best topic quality)\n",
        "- This makes the analysis **data-driven** rather than arbitrary\n",
        "\n",
        "**3. The Workflow**\n",
        "1. Extract spatial neighborhoods around each cell\n",
        "2. Use coherence analysis to find optimal number of topics\n",
        "3. Apply LDA topic modeling with optimal topics\n",
        "4. Use scimap's spatial_lda with the data-driven topic number\n",
        "5. Visualize and interpret discovered spatial patterns\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Prerequisites\n",
        "\n",
        "- IMC data with:\n",
        "  - Expression matrix (cells √ó features)\n",
        "  - Metadata with: X/Y coordinates, cell types, image IDs\n",
        "- Required packages: `scimap`, `anndata`, `scanpy`, `gensim`, `pyLDAvis`\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "1. **Load your data** (Section 2) - Update file paths and column names\n",
        "2. **Run coherence analysis** (Section 5) - Determines optimal topics\n",
        "3. **Apply spatial LDA** (Section 8) - Uses optimal topic number\n",
        "4. **Visualize results** (Section 10) - Explore discovered patterns\n",
        "\n",
        "**Note**: All column names (e.g., `Location_Center_X`, `major_celltype`) should be adjusted to match your metadata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import scimap as sm\n",
        "import anndata as ad\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning and topic modeling\n",
        "from sklearn.neighbors import BallTree\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "\n",
        "# Visualization\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "# Settings\n",
        "sns.set(color_codes=True)\n",
        "sc.settings.verbosity = 3\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data\n",
        "\n",
        "Load your IMC expression data and metadata. Adjust file paths and column names to match your data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTION A: Load your own data\n",
        "# Uncomment and adjust paths:\n",
        "# data = pd.read_csv('expression_data.csv')  # Expression matrix (cells x features)\n",
        "# meta = pd.read_csv('metadata.csv')        # Cell metadata (cells x annotations)\n",
        "# adata = ad.AnnData(data)\n",
        "# adata.obs = meta\n",
        "\n",
        "# OPTION B: Generate sample data for testing\n",
        "# Uncomment to generate synthetic IMC data:\n",
        "print(\"Generating sample IMC data for demonstration...\")\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic data\n",
        "n_cells = 2000\n",
        "n_features = 10\n",
        "n_images = 3\n",
        "\n",
        "# Expression data (random for demo)\n",
        "data = pd.DataFrame(\n",
        "    np.random.rand(n_cells, n_features),\n",
        "    columns=[f'Marker_{i+1}' for i in range(n_features)]\n",
        ")\n",
        "\n",
        "# Metadata with spatial coordinates and cell types\n",
        "cell_types = ['T_cell', 'B_cell', 'Macrophage', 'Tumor', 'Stroma']\n",
        "meta = pd.DataFrame({\n",
        "    'Location_Center_X': np.random.uniform(0, 1000, n_cells),\n",
        "    'Location_Center_Y': np.random.uniform(0, 1000, n_cells),\n",
        "    'major_celltype': np.random.choice(cell_types, n_cells),\n",
        "    'ImageNumber': np.random.choice(range(1, n_images+1), n_cells),\n",
        "    'celltype_detail': np.random.choice(cell_types, n_cells)  # For optional analyses\n",
        "})\n",
        "\n",
        "# Create AnnData object\n",
        "adata = ad.AnnData(data)\n",
        "adata.obs = meta\n",
        "\n",
        "print(f\"‚úì Generated {adata.n_obs} cells and {adata.n_vars} features\")\n",
        "print(f\"‚úì Metadata columns: {list(adata.obs.columns)}\")\n",
        "print(f\"‚úì Cell types: {adata.obs['major_celltype'].unique()}\")\n",
        "print(f\"‚úì Images: {adata.obs['ImageNumber'].unique()}\")\n",
        "print(\"\\nNote: This is synthetic data. Replace with your own data for real analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extract Spatial Neighborhoods\n",
        "\n",
        "This function extracts spatial neighborhoods around each cell, which will be used as \"documents\" for topic modeling. This is needed to perform coherence analysis for optimal topic selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_spatial_neighborhoods(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n",
        "                                  phenotype='phenotype', method='radius', radius=30, \n",
        "                                  imageid='imageid', subset=None):\n",
        "    \"\"\"\n",
        "    Extract spatial neighborhoods for each cell.\n",
        "    \n",
        "    Parameters:\n",
        "    ----------\n",
        "    adata : AnnData\n",
        "        Annotated data object\n",
        "    x_coordinate : str\n",
        "        Column name for X coordinates\n",
        "    y_coordinate : str\n",
        "        Column name for Y coordinates\n",
        "    phenotype : str\n",
        "        Column name for cell phenotypes/types\n",
        "    method : str\n",
        "        Method for neighborhood identification ('radius' or 'knn')\n",
        "    radius : float\n",
        "        Radius in pixels for neighborhood identification\n",
        "    imageid : str\n",
        "        Column name for image IDs\n",
        "    subset : int or None\n",
        "        Process specific image ID or None for all images\n",
        "        \n",
        "    Returns:\n",
        "    -------\n",
        "    all_neighborhoods : list\n",
        "        List of neighborhoods (each is a list of cell phenotypes)\n",
        "    \"\"\"\n",
        "    def process_image(adata_subset, x_coordinate, y_coordinate, phenotype, method, radius, imageid):\n",
        "        \"\"\"Process a single image.\"\"\"\n",
        "        image_id = np.unique(adata_subset.obs[imageid])[0]\n",
        "        print(f'Processing image: {image_id}')\n",
        "        \n",
        "        # Create DataFrame with coordinates and phenotypes\n",
        "        df = pd.DataFrame({\n",
        "            'x': adata_subset.obs[x_coordinate],\n",
        "            'y': adata_subset.obs[y_coordinate],\n",
        "            'phenotype': adata_subset.obs[phenotype]\n",
        "        })\n",
        "        \n",
        "        # Find neighbors using BallTree\n",
        "        if method == 'radius':\n",
        "            print(f\"  Identifying neighbours within {radius} pixels of every cell\")\n",
        "            kdt = BallTree(df[['x', 'y']], leaf_size=2)\n",
        "            neighbor_indices = kdt.query_radius(df[['x', 'y']], r=radius, return_distance=False)\n",
        "        \n",
        "        # Map indices to phenotypes\n",
        "        phenotype_map = dict(zip(range(len(neighbor_indices)), df['phenotype']))\n",
        "        neighborhoods = []\n",
        "        for indices in neighbor_indices:\n",
        "            neighborhoods.append([phenotype_map[idx] for idx in indices])\n",
        "        \n",
        "        return neighborhoods\n",
        "    \n",
        "    # Process all images or subset\n",
        "    if subset is not None:\n",
        "        adata_list = [adata[adata.obs[imageid] == subset]]\n",
        "    else:\n",
        "        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n",
        "    \n",
        "    # Extract neighborhoods for all images\n",
        "    all_neighborhoods = []\n",
        "    for adata_subset in adata_list:\n",
        "        neighborhoods = process_image(adata_subset, x_coordinate, y_coordinate, \n",
        "                                     phenotype, method, radius, imageid)\n",
        "        all_neighborhoods.extend(neighborhoods)\n",
        "    \n",
        "    return all_neighborhoods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract spatial neighborhoods\n",
        "# Adjust column names to match your metadata\n",
        "spatial_neighborhoods = extract_spatial_neighborhoods(\n",
        "    adata,\n",
        "    x_coordinate='Location_Center_X',    # X coordinate column name\n",
        "    y_coordinate='Location_Center_Y',    # Y coordinate column name\n",
        "    phenotype='major_celltype',         # Cell type/phenotype column name\n",
        "    method='radius',\n",
        "    radius=30,                           # Neighborhood radius in pixels\n",
        "    imageid='ImageNumber',               # Image ID column name\n",
        "    subset=None                          # None = process all images\n",
        ")\n",
        "\n",
        "print(f\"\\nExtracted {len(spatial_neighborhoods)} spatial neighborhoods\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prepare Data for Topic Modeling\n",
        "\n",
        "Convert spatial neighborhoods to the format required by Gensim LDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert neighborhoods to list of lists (documents)\n",
        "texts = spatial_neighborhoods\n",
        "\n",
        "# Create dictionary mapping cell types to IDs\n",
        "id2word = corpora.Dictionary(texts)\n",
        "\n",
        "# Create corpus (bag of words representation)\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "print(f\"Total neighborhoods (documents): {len(corpus)}\")\n",
        "print(f\"Unique cell types (vocabulary size): {len(id2word)}\")\n",
        "print(f\"\\nCell types in vocabulary: {list(id2word.values())[:10]}...\")  # Show first 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Coherence Analysis for Optimal Topic Selection\n",
        "\n",
        "This step determines the optimal number of topics by computing coherence scores for different topic numbers. Higher coherence indicates better topic quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=2, random_state=0):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "        Dictionary mapping words to IDs\n",
        "    corpus : list\n",
        "        Gensim corpus (bag of words)\n",
        "    texts : list\n",
        "        List of input texts (neighborhoods)\n",
        "    limit : int\n",
        "        Maximum number of topics to test\n",
        "    start : int\n",
        "        Starting number of topics\n",
        "    step : int\n",
        "        Step size for topic numbers\n",
        "    random_state : int\n",
        "        Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : list\n",
        "        List of LDA topic models\n",
        "    coherence_values : list\n",
        "        Coherence values corresponding to each model\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    \n",
        "    for num_topics in range(start, limit, step):\n",
        "        print(f\"Testing {num_topics} topics...\")\n",
        "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, \n",
        "                        random_state=random_state, passes=10, alpha='auto', per_word_topics=True)\n",
        "        model_list.append(model)\n",
        "        \n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, \n",
        "                                       coherence='c_v')\n",
        "        coherence = coherencemodel.get_coherence()\n",
        "        coherence_values.append(coherence)\n",
        "        print(f\"  Coherence score: {coherence:.4f}\")\n",
        "    \n",
        "    return model_list, coherence_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute coherence for different numbers of topics\n",
        "limit = 12      # Maximum number of topics to test\n",
        "start = 4       # Starting number of topics\n",
        "step = 2        # Step size\n",
        "\n",
        "model_list, coherence_values = compute_coherence_values(\n",
        "    dictionary=id2word,\n",
        "    corpus=corpus,\n",
        "    texts=texts,\n",
        "    start=start,\n",
        "    limit=limit,\n",
        "    step=step,\n",
        "    random_state=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot coherence values\n",
        "x = range(start, limit, step)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, coherence_values, marker='o', linewidth=2, markersize=8)\n",
        "plt.xlabel(\"Number of Topics\", fontsize=12)\n",
        "plt.ylabel(\"Coherence Score\", fontsize=12)\n",
        "plt.title(\"Topic Model Coherence Analysis\", fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print results\n",
        "print(\"\\nCoherence Scores:\")\n",
        "for num_topics, coherence in zip(x, coherence_values):\n",
        "    print(f\"  {num_topics} topics: {coherence:.4f}\")\n",
        "\n",
        "# Find optimal number of topics (highest coherence)\n",
        "optimal_idx = np.argmax(coherence_values)\n",
        "optimal_topics = x[optimal_idx]\n",
        "optimal_coherence = coherence_values[optimal_idx]\n",
        "\n",
        "print(f\"\\n‚úì Optimal number of topics: {optimal_topics} (coherence: {optimal_coherence:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Build Final LDA Model with Optimal Topics\n",
        "\n",
        "Use the optimal number of topics determined from coherence analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build final LDA model with optimal number of topics\n",
        "# You can also manually set num_topics if you prefer\n",
        "num_topics = optimal_topics  # or set manually, e.g., num_topics = 6\n",
        "\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    num_topics=num_topics,\n",
        "    random_state=0,\n",
        "    passes=20,           # Number of passes through the corpus\n",
        "    alpha='auto',        # Automatic alpha estimation\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "print(f\"LDA model created with {num_topics} topics\")\n",
        "\n",
        "# Display topics\n",
        "print(\"\\nTop words for each topic:\")\n",
        "for idx, topic in lda_model.print_topics(-1, num_words=5):\n",
        "    print(f\"\\nTopic {idx}:\")\n",
        "    print(topic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualize Topics with pyLDAvis\n",
        "\n",
        "### Interactive Topic Exploration\n",
        "pyLDAvis provides an interactive visualization where you can:\n",
        "- See which cell types are most associated with each topic\n",
        "- Explore topic similarity and overlap\n",
        "- Understand the relative importance of topics\n",
        "\n",
        "**Note**: This visualization helps validate that topics are meaningful and interpretable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare visualization\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = gensimvis.prepare(lda_model, corpus, id2word, sort_topics=False)\n",
        "vis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Apply Spatial LDA using scimap\n",
        "\n",
        "### The Key Step\n",
        "Now we use scimap's built-in `spatial_lda` function with the **optimal number of topics** determined from coherence analysis. This is the main analysis that assigns each cell a probability distribution over spatial motifs.\n",
        "\n",
        "### What Gets Stored\n",
        "- Results in `adata.uns['spatial_lda']`: Matrix of cells √ó topics (motif probabilities)\n",
        "- Each cell gets a probability score for each discovered spatial motif\n",
        "- Higher probability = cell is more likely to be part of that spatial pattern\n",
        "\n",
        "### Why This Matters\n",
        "By using the data-driven optimal topic number, we ensure the discovered motifs are:\n",
        "- **Meaningful**: High coherence = interpretable patterns\n",
        "- **Appropriate**: Not too few (missing structure) or too many (overfitting)\n",
        "- **Reproducible**: Based on data properties, not arbitrary choices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply scimap's spatial_lda with optimal number of topics\n",
        "sm.tl.spatial_lda(\n",
        "    adata,\n",
        "    x_coordinate='Location_Center_X',\n",
        "    y_coordinate='Location_Center_Y',\n",
        "    phenotype='major_celltype',\n",
        "    method='radius',\n",
        "    radius=30,\n",
        "    knn=60,\n",
        "    imageid='ImageNumber',\n",
        "    num_motifs=num_topics,  # Use optimal number from coherence analysis\n",
        "    random_state=0,\n",
        "    subset=None,\n",
        "    label='spatial_lda'\n",
        ")\n",
        "\n",
        "print(f\"\\nSpatial LDA completed. Results stored in adata.uns['spatial_lda']\")\n",
        "print(f\"Shape: {adata.uns['spatial_lda'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Cluster Spatial Motifs\n",
        "\n",
        "### Purpose\n",
        "Group cells with similar spatial motif profiles together. This creates spatial \"communities\" or \"regions\" in the tissue.\n",
        "\n",
        "### What Happens\n",
        "- K-means clustering on the motif probability matrix\n",
        "- Cells with similar motif profiles cluster together\n",
        "- Creates discrete spatial groups (e.g., \"spatial-0\", \"spatial-1\", etc.)\n",
        "\n",
        "### Adjustable\n",
        "- `n_clusters`: Number of spatial groups to identify (default: 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill NaN values and cluster spatial motifs\n",
        "adata.uns['spatial_lda'] = adata.uns['spatial_lda'].fillna(0)\n",
        "\n",
        "# K-means clustering of spatial motifs\n",
        "n_clusters = 6  # Adjust based on your data\n",
        "kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=0)\n",
        "kmeans.fit(adata.uns['spatial_lda'])\n",
        "\n",
        "# Add cluster labels to metadata\n",
        "cluster_labels = ['spatial-' + str(label) for label in kmeans.labels_]\n",
        "adata.obs['spatial_kmeans'] = cluster_labels\n",
        "\n",
        "print(f\"Clustered cells into {n_clusters} spatial groups\")\n",
        "print(f\"\\nCluster distribution:\")\n",
        "print(adata.obs['spatial_kmeans'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualize Spatial Motifs\n",
        "\n",
        "### Visualizations Provided\n",
        "\n",
        "1. **Dot Plot**: Shows which cell types are enriched in each spatial cluster\n",
        "2. **Stacked Bar Plot**: Shows cell type composition proportions across spatial clusters\n",
        "3. **Voronoi Plot**: Spatial map showing where each spatial cluster appears in tissue\n",
        "\n",
        "### Interpretation Tips\n",
        "- **Spatial clusters** represent regions with distinct cellular organization\n",
        "- Compare cell type compositions between clusters to understand what makes each region unique\n",
        "- Voronoi plots show the spatial distribution - are clusters localized or dispersed?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dot plot showing cell type composition of each spatial cluster\n",
        "sc.pl.dotplot(\n",
        "    adata,\n",
        "    var_names=adata.var.index,\n",
        "    groupby='spatial_kmeans',\n",
        "    dendrogram=False,\n",
        "    use_raw=False,\n",
        "    expression_cutoff=0.6,\n",
        "    standard_scale='var',\n",
        "    cmap='magma'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stacked bar plot showing cell type proportions in each spatial cluster\n",
        "sm.pl.stacked_barplot(\n",
        "    adata,\n",
        "    x_axis='spatial_kmeans',\n",
        "    y_axis='major_celltype',\n",
        "    method='percent',\n",
        "    plot_tool='matplotlib',\n",
        "    figsize=(10, 10),\n",
        "    matplotlib_cmap='Paired'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Voronoi plot showing spatial distribution of motifs\n",
        "# Adjust subset to visualize specific images\n",
        "sc.set_figure_params(dpi=100, dpi_save=200)\n",
        "\n",
        "sm.pl.voronoi(\n",
        "    adata,\n",
        "    color_by='spatial_kmeans',\n",
        "    colors=None,\n",
        "    x_coordinate='Location_Center_X',\n",
        "    y_coordinate='Location_Center_Y',\n",
        "    imageid='ImageNumber',\n",
        "    subset=1,  # Change to visualize different images\n",
        "    voronoi_edge_color='black',\n",
        "    voronoi_line_width=0.2,\n",
        "    voronoi_alpha=1,\n",
        "    overlay_points_categories=None,\n",
        "    overlay_drop_categories=None,\n",
        "    overlay_point_size=5,\n",
        "    overlay_point_alpha=1,\n",
        "    overlay_point_shape=\".\",\n",
        "    plot_legend=True,\n",
        "    legend_size=6,\n",
        "    figsize=(15, 15)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Additional Spatial Analyses (Optional)\n",
        "\n",
        "### Complementary Analyses\n",
        "\n",
        "These scimap functions provide additional spatial insights:\n",
        "\n",
        "1. **Spatial Proximity Score**: Measures how often specific cell types are found near each other\n",
        "2. **Spatial Distance**: Calculates distances between cell types\n",
        "3. **Spatial Interaction**: Tests for significant co-localization between cell type pairs\n",
        "\n",
        "**Note**: Adjust cell type names in these sections to match your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spatial proximity score\n",
        "sm.tl.spatial_pscore(\n",
        "    adata,\n",
        "    proximity=['Bcell', 'CD4'],  # Adjust to your cell types of interest\n",
        "    score_by='ImageNumber',\n",
        "    x_coordinate='Location_Center_X',\n",
        "    y_coordinate='Location_Center_Y',\n",
        "    phenotype='celltype_detail',  # Adjust to your detailed cell type column\n",
        "    method='radius',\n",
        "    radius=20,\n",
        "    knn=3,\n",
        "    imageid='ImageNumber',\n",
        "    subset=None,\n",
        "    label='spatial_pscore'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spatial distance analysis\n",
        "sm.tl.spatial_distance(\n",
        "    adata,\n",
        "    x_coordinate='Location_Center_X',\n",
        "    y_coordinate='Location_Center_Y',\n",
        "    phenotype='major_celltype',\n",
        "    subset=None,\n",
        "    imageid='ImageNumber',\n",
        "    label='spatial_distance'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spatial interaction analysis\n",
        "sm.tl.spatial_interaction(\n",
        "    adata,\n",
        "    x_coordinate='Location_Center_X',\n",
        "    y_coordinate='Location_Center_Y',\n",
        "    phenotype='major_celltype',\n",
        "    method='radius',\n",
        "    radius=30,\n",
        "    knn=10,\n",
        "    permutation=1000,\n",
        "    imageid='ImageNumber',\n",
        "    subset=None,\n",
        "    pval_method='zscore',\n",
        "    label='spatial_interaction'\n",
        ")\n",
        "\n",
        "# Visualize spatial interactions\n",
        "sm.pl.spatial_interaction(\n",
        "    adata,\n",
        "    summarize_plot=False,\n",
        "    row_cluster=False,\n",
        "    col_cluster=False,\n",
        "    yticklabels=True,\n",
        "    p_val=0.05\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What This Notebook Achieves\n",
        "\n",
        "1. **Data-Driven Topic Selection**: Coherence analysis determines optimal number of spatial motifs\n",
        "2. **Spatial Pattern Discovery**: Identifies recurring cellular organization patterns in tissue\n",
        "3. **Interpretable Results**: High coherence ensures discovered motifs are biologically meaningful\n",
        "4. **Comprehensive Analysis**: From topic modeling to spatial visualization\n",
        "\n",
        "### Key Innovation\n",
        "\n",
        "**The coherence workflow solves a critical problem**: Instead of guessing how many topics to use, we let the data tell us. This makes spatial LDA analysis:\n",
        "- ‚úÖ **Reproducible**: Same data ‚Üí same optimal topics\n",
        "- ‚úÖ **Interpretable**: High coherence = clear, meaningful patterns\n",
        "- ‚úÖ **Robust**: Less sensitive to arbitrary parameter choices\n",
        "\n",
        "### Expected Outputs\n",
        "\n",
        "- Optimal number of topics (from coherence analysis)\n",
        "- Spatial motif assignments for each cell\n",
        "- Spatial clusters showing distinct tissue regions\n",
        "- Visualizations of spatial patterns\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Interpret discovered spatial motifs biologically\n",
        "- Compare motifs across different conditions/groups\n",
        "- Validate findings with domain knowledge\n",
        "- Use motifs as features for downstream analyses\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Notes for Users\n",
        "\n",
        "- **Column names**: Update all column references to match your metadata\n",
        "- **File paths**: Update data loading paths to your data location\n",
        "- **Parameters**: Adjust radius, topic ranges, cluster numbers based on your data scale\n",
        "- **Cell types**: Update cell type names in optional analyses sections\n",
        "\n",
        "---\n",
        "\n",
        "## üîó References\n",
        "\n",
        "- Scimap documentation: https://scimap.readthedocs.io/\n",
        "- LDA topic modeling: Blei et al. (2003) JMLR\n",
        "- Coherence metrics: R√∂der et al. (2015) EMNLP"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
